import torch
import numpy as np
import random
import os
from app.config import Config
from app.data.loader import create_federated_datasets, get_dataloaders
from app.models.classifier import get_model
from app.attacks.adversarial import AdversarialAttacks
from app.models.detector import PoisonDetector
from app.federated.learning import FederatedLearning
from torch.utils.data import DataLoader, ConcatDataset

def set_seed(seed=Config.RANDOM_SEED):
    """Fixer les seeds pour la reproductibilit√©"""
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True

def print_header(text):
    """Afficher un en-t√™te format√©"""
    print(f"\n{'='*70}")
    print(f"  {text}")
    print(f"{'='*70}\n")

def main():
    # Configuration initiale
    set_seed()
    
    print_header("üöÄ SYST√àME DE D√âTECTION D'ATTAQUES ADVERSARIALES")
    print(f"Device utilis√©: {Config.DEVICE}")
    print(f"GPU disponible: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"GPU: {torch.cuda.get_device_name(0)}")
        print(f"M√©moire GPU: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
    
    # √âtape 1: Charger les donn√©es
    print_header("üìÅ √âTAPE 1: CHARGEMENT DES DONN√âES")
    
    if not os.path.exists(Config.DATASET_PATH):
        print("‚ùå Dataset non trouv√©!")
        print("Ex√©cutez d'abord: python download_data.py")
        return
    
    # Cr√©er les datasets f√©d√©r√©s
    hospital_datasets = create_federated_datasets(Config.DATASET_PATH)
    print(f"‚úì {Config.NUM_HOSPITALS} h√¥pitaux cr√©√©s")
    for i, dataset in enumerate(hospital_datasets):
        print(f"  - H√¥pital {i+1}: {len(dataset)} images")
    
    # Charger les donn√©es de test
    test_loader, val_loader = get_dataloaders(Config.DATASET_PATH)
    print(f"‚úì Dataset de test: {len(test_loader.dataset)} images")
    print(f"‚úì Dataset de validation: {len(val_loader.dataset)} images")
    
    # √âtape 2: Pr√©-entra√Ænement du mod√®le
    print_header("üß† √âTAPE 2: PR√â-ENTRA√éNEMENT DU MOD√àLE")
    
    pretrained_model = get_model(pretrained=True)
    print("‚úì Mod√®le ResNet18 pr√©-entra√Æn√© charg√©")
    
    # √âtape 3: G√©n√©ration d'attaques adversariales
    print_header("‚öîÔ∏è √âTAPE 3: G√âN√âRATION D'ATTAQUES ADVERSARIALES")
    
    print("G√©n√©ration d'exemples adversariaux FGSM et PGD...")
    
    # Utiliser les deux premiers datasets d'h√¥pitaux pour l'entra√Ænement du d√©tecteur
    print("Assemblage des donn√©es des H√¥pitaux 1 et 2 pour l'entra√Ænement du d√©tecteur...")
    detector_training_data = ConcatDataset([hospital_datasets[0], hospital_datasets[1]])
    
    sample_loader = DataLoader(
        detector_training_data,
        batch_size=Config.BATCH_SIZE,
        shuffle=False,
        num_workers=2
    )
    
    # G√©n√©rer des exemples adversariaux FGSM
    print("\nüéØ G√©n√©ration d'attaques FGSM...")
    fgsm_data = AdversarialAttacks.generate_adversarial_dataset(
        pretrained_model, 
        sample_loader, 
        attack_type='fgsm',
        ratio=0.3
    )
    print(f"‚úì {len(fgsm_data)} exemples g√©n√©r√©s (30% adversariaux)")
    
    # G√©n√©rer des exemples adversariaux PGD
    print("\nüéØ G√©n√©ration d'attaques PGD...")
    pgd_data = AdversarialAttacks.generate_adversarial_dataset(
        pretrained_model,
        sample_loader,
        attack_type='pgd',
        ratio=0.3
    )
    print(f"‚úì {len(pgd_data)} exemples g√©n√©r√©s (30% adversariaux)")
    
    # Combiner les donn√©es
    adversarial_train_data = fgsm_data + pgd_data
    print(f"\n‚úì Total d'exemples d'entra√Ænement: {len(adversarial_train_data)}")
    
    # Split Train/Val (80/20)
    random.shuffle(adversarial_train_data)
    split_idx = int(0.8 * len(adversarial_train_data))
    train_set = adversarial_train_data[:split_idx]
    val_set = adversarial_train_data[split_idx:]
    print(f"‚úì Split Train: {len(train_set)}, Val: {len(val_set)}")
    
    # √âtape 4: Entra√Ænement du d√©tecteur d'attaques
    print_header("üîç √âTAPE 4: ENTRA√éNEMENT DU D√âTECTEUR")
    
    poison_detector = PoisonDetector(pretrained_model)
    poison_detector.train_detector(train_set, val_data=val_set, epochs=10)
    poison_detector.save_detector("poison_detector.pth")
    
    # √âtape 5: Filtrage des donn√©es empoisonn√©es
    print_header("üßπ √âTAPE 5: FILTRAGE DES DONN√âES")
    
    # Cr√©er un loader avec des donn√©es potentiellement empoisonn√©es
    # On utilise l'H√¥pital 3 car les 1 et 2 ont servi √† l'entra√Ænement
    poisoned_loader = DataLoader(
        hospital_datasets[2],
        batch_size=Config.BATCH_SIZE,
        shuffle=False,
        num_workers=2
    )
    
    # G√©n√©rer des attaques sur ce dataset
    print("Contamination du dataset avec des attaques...")
    attacked_data = AdversarialAttacks.generate_adversarial_dataset(
        pretrained_model,
        poisoned_loader,
        attack_type='pgd',
        ratio=0.4
    )
    
    # Cr√©er un loader avec les donn√©es attaqu√©es
    from torch.utils.data import TensorDataset
    attacked_images = torch.cat([item[0] for item in attacked_data])
    attacked_labels = torch.tensor([item[1].item() for item in attacked_data])
    attacked_dataset = TensorDataset(attacked_images, attacked_labels)
    attacked_loader = DataLoader(
        attacked_dataset,
        batch_size=Config.BATCH_SIZE,
        shuffle=False
    )
    
    # Filtrer les donn√©es
    # Charger le meilleur d√©tecteur pour le filtrage
    if os.path.exists("poison_detector_best.pth"):
        poison_detector.load_detector("poison_detector_best.pth")
        print("‚úì Meilleur d√©tecteur charg√© pour le filtrage")
        
    clean_data = poison_detector.filter_clean_data(attacked_loader)
    
    # √âtape 6: Apprentissage f√©d√©r√© avec donn√©es propres
    print_header("üè• √âTAPE 6: APPRENTISSAGE F√âD√âR√â")
    
    # Cr√©er un nouveau mod√®le global
    global_model = get_model(pretrained=True)
    
    # Initialiser l'apprentissage f√©d√©r√©
    fed_learning = FederatedLearning(global_model)
    
    # Entra√Æner de mani√®re f√©d√©r√©e
    final_model = fed_learning.federated_training(hospital_datasets, test_loader=test_loader)
    
    # √âtape 7: √âvaluation finale
    print_header("üìä √âTAPE 7: √âVALUATION FINALE")
    
    # √âvaluer le mod√®le global
    accuracy = fed_learning.evaluate_global_model(test_loader)
    
    # Tester la robustesse contre les attaques
    print("\nüõ°Ô∏è Test de robustesse contre les attaques...")
    
    # G√©n√©rer des exemples adversariaux sur le test set
    test_adv_fgsm = []
    test_adv_pgd = []
    
    for images, labels in test_loader:
        images = images.to(Config.DEVICE)
        labels = labels.to(Config.DEVICE)
        
        # FGSM
        adv_fgsm = AdversarialAttacks.fgsm_attack(final_model, images, labels)
        test_adv_fgsm.append((adv_fgsm, labels))
        
        # PGD
        adv_pgd = AdversarialAttacks.pgd_attack(final_model, images, labels)
        test_adv_pgd.append((adv_pgd, labels))
    
    # √âvaluer sur les donn√©es adversariales
    print("\n√âvaluation sur donn√©es originales:")
    print(f"  Accuracy: {accuracy:.2f}%")
    
    # Sauvegarder les mod√®les
    print_header("üíæ SAUVEGARDE DES MOD√àLES")
    fed_learning.save_global_model("global_model_final.pth")
    
    print_header("‚úÖ PROCESSUS TERMIN√â AVEC SUCC√àS")
    print("Fichiers g√©n√©r√©s:")
    print("  - poison_detector.pth")
    print("  - global_model_final.pth")
    print("\nVous pouvez maintenant utiliser ces mod√®les pour:")
    print("  1. D√©tecter les attaques adversariales")
    print("  2. Classifier les radiographies thoraciques")
    print("  3. Poursuivre l'entra√Ænement f√©d√©r√©")

if __name__ == "__main__":
    main()