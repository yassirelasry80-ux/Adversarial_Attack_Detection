import torch
import numpy as np
import random
import os
from app.config import Config
from app.data.loader import create_federated_datasets, get_dataloaders
from app.models.classifier import get_model
from app.attacks.adversarial import AdversarialAttacks
import argparse
from app.models.detector import PoisonDetector, AutoEncoderDetector
from torch.utils.data import DataLoader, ConcatDataset, TensorDataset
from app.federated.learning import FederatedLearning

def set_seed(seed=Config.RANDOM_SEED):
    """Fixer les seeds pour la reproductibilit√©"""
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True

def print_header(text):
    """Afficher un en-t√™te format√©"""
    print(f"\n{'='*70}")
    print(f"  {text}")
    print(f"{'='*70}\n")


def main():
    parser = argparse.ArgumentParser(description='Adversarial Attack Detection')
    parser.add_argument('--method', type=str, default='supervised', 
                      choices=['supervised', 'autoencoder'],
                      help='Method for detection: supervised or autoencoder')
    args = parser.parse_args()

    # Configuration initiale
    set_seed()
    
    print_header(f"üöÄ SYST√àME DE D√âTECTION D'ATTAQUES ADVERSARIALES ({args.method.upper()})")
    print(f"Device utilis√©: {Config.DEVICE}")
    print(f"GPU disponible: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"GPU: {torch.cuda.get_device_name(0)}")
        print(f"M√©moire GPU: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
    
    # √âtape 1: Charger les donn√©es
    print_header("üìÅ √âTAPE 1: CHARGEMENT DES DONN√âES")
    
    if not os.path.exists(Config.DATASET_PATH):
        print("‚ùå Dataset non trouv√©!")
        print("Ex√©cutez d'abord: python download_data.py")
        return
    
    # Cr√©er les datasets f√©d√©r√©s
    hospital_datasets = create_federated_datasets(Config.DATASET_PATH)
    print(f"‚úì {Config.NUM_HOSPITALS} h√¥pitaux cr√©√©s")
    for i, dataset in enumerate(hospital_datasets):
        print(f"  - H√¥pital {i+1}: {len(dataset)} images")
    
    # Charger les donn√©es de test
    test_loader, val_loader = get_dataloaders(Config.DATASET_PATH)
    print(f"‚úì Dataset de test: {len(test_loader.dataset)} images")
    print(f"‚úì Dataset de validation: {len(val_loader.dataset)} images")
    
    # √âtape 2: Pr√©-entra√Ænement du mod√®le
    print_header("üß† √âTAPE 2: PR√â-ENTRA√éNEMENT DU MOD√àLE")
    
    pretrained_model = get_model(pretrained=True)
    print("‚úì Mod√®le ResNet18 pr√©-entra√Æn√© charg√©")
    
    # √âtape 3: G√©n√©ration d'attaques adversariales
    print_header("‚öîÔ∏è √âTAPE 3: G√âN√âRATION D'ATTAQUES ADVERSARIALES")
    
    print("G√©n√©ration d'exemples adversariaux FGSM et PGD...")
    
    # Utiliser les deux premiers datasets d'h√¥pitaux pour l'entra√Ænement du d√©tecteur
    print("Assemblage des donn√©es des H√¥pitaux 1 et 2 pour l'entra√Ænement du d√©tecteur...")
    detector_training_data = ConcatDataset([hospital_datasets[0], hospital_datasets[1]])
    
    sample_loader = DataLoader(
        detector_training_data,
        batch_size=Config.BATCH_SIZE,
        shuffle=False,
        num_workers=2
    )
    
    # G√©n√©rer des exemples adversariaux FGSM
    print("\nüéØ G√©n√©ration d'attaques FGSM...")
    fgsm_data = AdversarialAttacks.generate_adversarial_dataset(
        pretrained_model, 
        sample_loader, 
        attack_type='fgsm',
        ratio=0.3
    )
    print(f"‚úì {len(fgsm_data)} exemples g√©n√©r√©s (30% adversariaux)")
    
    # G√©n√©rer des exemples adversariaux PGD
    print("\nüéØ G√©n√©ration d'attaques PGD...")
    pgd_data = AdversarialAttacks.generate_adversarial_dataset(
        pretrained_model,
        sample_loader,
        attack_type='pgd',
        ratio=0.3
    )
    print(f"‚úì {len(pgd_data)} exemples g√©n√©r√©s (30% adversariaux)")
    
    # Combiner les donn√©es
    adversarial_train_data = fgsm_data + pgd_data
    print(f"\n‚úì Total d'exemples d'entra√Ænement: {len(adversarial_train_data)}")
    
    # Split Train/Val (80/20)
    random.shuffle(adversarial_train_data)
    split_idx = int(0.8 * len(adversarial_train_data))
    train_set = adversarial_train_data[:split_idx]
    val_set = adversarial_train_data[split_idx:]
    print(f"‚úì Split Train: {len(train_set)}, Val: {len(val_set)}")
    
    # √âtape 4: Entra√Ænement et Comparaison des d√©tecteurs
    print_header("üîç √âTAPE 4: ENTRA√éNEMENT ET COMPARAISON DES D√âTECTEURS")
    
    # --- 1. Entra√Ænement Supervis√© ---
    print("\n[1/2] Entra√Ænement du D√©tecteur Supervis√© (MLP)...")
    detector_sup = PoisonDetector(pretrained_model)
    detector_sup.train_detector(train_set, val_data=val_set, epochs=5) # Reduced epochs for speed
    detector_sup.save_detector("poison_detector.pth")
    
    # --- 2. Entra√Ænement Auto-Encodeur ---
    print("\n[2/2] Entra√Ænement du D√©tecteur Auto-Encodeur...")
    detector_ae = AutoEncoderDetector()
    detector_ae.train_detector(train_set, val_data=val_set, epochs=5) # Reduced epochs for speed
    detector_ae.save_detector("autoencoder.pth")
    
    # --- 3. Comparaison ---
    print_header("üìä COMPARAISON DES PERFORMANCES")
    
    # Evaluation sur le set de validation (mixte)
    print("√âvaluation sur le dataset de validation mixte (Clean + Attacks)...")
    
    def evaluate_detector(det_model, val_data, name):
        correct = 0
        total = 0
        
        # Pr√©parer les donn√©es
        images = torch.cat([item[0] for item in val_data]).to(Config.DEVICE)
        labels = torch.tensor([item[2] for item in val_data]).to(Config.DEVICE) # item[2] is is_adversarial
        
        is_poisoned, _ = det_model.detect_poison(images)
        is_poisoned = is_poisoned.to(Config.DEVICE)
        
        correct = (is_poisoned == labels).sum().item()
        total = len(labels)
        acc = 100. * correct / total
        return acc

    acc_sup = evaluate_detector(detector_sup, val_set, "Supervis√©")
    acc_ae = evaluate_detector(detector_ae, val_set, "Auto-Encodeur")
    
    print(f"\nPr√©cision de d√©tection (Accuracy):")
    print(f"  1. Supervis√© (MLP)       : {acc_sup:.2f}%")
    print(f"  2. Auto-Encodeur (Seuil) : {acc_ae:.2f}%")
    
    # --- 4. Choix de l'utilisateur ---
    print("\n" + "="*50)
    print("ü§î CHOIX DU D√âTECTEUR POUR LA F√âD√âRATION")
    print("="*50)
    print("Quel d√©tecteur voulez-vous utiliser pour prot√©ger les h√¥pitaux ?")
    print("1: Supervis√© (MLP)")
    print("2: Auto-Encodeur (Non-supervis√©)")
    
    while True:
        choice = input("\nVotre choix (1 ou 2): ").strip()
        if choice == "1":
            selected_detector = detector_sup
            print(">> Vous avez choisi: SUPERVIS√â")
            break
        elif choice == "2":
            selected_detector = detector_ae
            print(">> Vous avez choisi: AUTO-ENCODEUR")
            break
        else:
            print("Choix invalide, r√©essayez.")

    # √âtape 5 & 6: D√©ploiement du D√©tecteur et Apprentissage F√©d√©r√©
    print_header("üè• √âTAPES 5 & 6: D√âPLOIEMENT ET F√âD√âRATION")
    print(f"D√©ploiement du d√©tecteur {choice} (S√©lectionn√©) √† l'entr√©e de chaque h√¥pital...")
    
    # Pr√©parer les sources de donn√©es pour chaque h√¥pital
    # H1, H2, H4 sont propres (Simulation normale)
    # H3 est attaqu√© (Simulation d'attaque)
    
    # Pour H3, on doit g√©n√©rer l'attaque MAINTENANT si ce n'est pas fait
    print("\n[Simulation] G√©n√©ration de l'attaque sur l'H√¥pital 3...")
    h3_loader = DataLoader(hospital_datasets[2], batch_size=Config.BATCH_SIZE)
    h3_attacked = AdversarialAttacks.generate_adversarial_dataset(
        pretrained_model, h3_loader, attack_type='pgd', ratio=0.5
    )
    # Convertir H3 en TensorDataset pour faciliter la suite
    h3_imgs = torch.cat([item[0] for item in h3_attacked])
    h3_lbls = torch.tensor([item[1].item() for item in h3_attacked])
    # Note: item[2] est le flag is_adv, on ne l'utilise pas pour le filtrage (c'est le d√©tecteur qui devine)
    dataset_h3_attacked = TensorDataset(h3_imgs, h3_lbls)
    
    # Liste des datasets "bruts" qui arrivent √† chaque h√¥pital
    raw_datasets_per_hospital = [
        hospital_datasets[0],      # H1 (Clean)
        hospital_datasets[1],      # H2 (Clean)
        dataset_h3_attacked,       # H3 (Attaqu√©!)
        hospital_datasets[3]       # H4 (Clean)
    ]
    
    fl_ready_datasets = []
    
    for i, raw_ds in enumerate(raw_datasets_per_hospital):
        print(f"\nüîí Filtrage H√¥pital {i+1}...")
        
        # Cr√©er loader temporaire
        loader = DataLoader(raw_ds, batch_size=Config.BATCH_SIZE, shuffle=False)
        
        # Le d√©tecteur filtre (rejette ce qu'il pense √™tre des attaques)
        clean_data_list = selected_detector.filter_clean_data(loader)
        
        # Reconvertir en Dataset pytorch
        if len(clean_data_list) > 0:
            c_imgs = torch.stack([item[0] for item in clean_data_list])
            c_lbls = torch.stack([item[1] for item in clean_data_list])
            clean_ds = TensorDataset(c_imgs, c_lbls)
            fl_ready_datasets.append(clean_ds)
            print(f"  -> Donn√©es accept√©es pour FL: {len(clean_ds)}/{len(raw_ds)}")
        else:
            print(f"  -> ‚ö†Ô∏è TOUTES les donn√©es ont √©t√© rejet√©es par le d√©tecteur !")
    
    # Lancement du FL
    print_header("üöÄ LANCEMENT DE L'APPRENTISSAGE F√âD√âR√â")
    
    if len(fl_ready_datasets) == 0:
        print("‚ùå Erreur: Plus aucune donn√©e disponible apr√®s filtrage.")
        return

    # Cr√©er un nouveau mod√®le global
    global_model = get_model(pretrained=True)
    
    # Initialiser l'apprentissage f√©d√©r√©
    fed_learning = FederatedLearning(global_model)
    
    # Entra√Æner de mani√®re f√©d√©r√©e AVEC les donn√©es filtr√©es
    final_model = fed_learning.federated_training(fl_ready_datasets, test_loader=test_loader)
    
    # √âtape 7: √âvaluation finale
    print_header("üìä √âTAPE 7: √âVALUATION FINALE DU MOD√àLE GLOBAL")
    
    # √âvaluer le mod√®le global
    accuracy = fed_learning.evaluate_global_model(test_loader)
    
    # Sauvegarder les mod√®les
    print_header("üíæ SAUVEGARDE DES RESULTATS")
    
    if choice == "1":
        global_model_name = "global_model_supervised.pth"
    else:
        global_model_name = "global_model_autoencoder.pth"
        
    fed_learning.save_global_model(global_model_name)
    
    print_header("‚úÖ PROCESSUS COMPLET TERMIN√â")
    print("R√©sum√©:")
    print("1. D√©tecteurs g√©n√©r√©s et compar√©s.")
    print("2. D√©tecteur choisi d√©ploy√© sur TOUS les h√¥pitaux.")
    print("3. H√¥pital 3 (Attaqu√©) a √©t√© filtr√©.")
    print("4. H√¥pitaux 1, 2, 4 (Sains) ont √©t√© v√©rifi√©s.")
    print(f"5. Apprentissage F√©d√©r√© ex√©cut√© sur les donn√©es valid√©es.")
    print(f"6. Mod√®le global sauvegard√© sous: {global_model_name}")

if __name__ == "__main__":
    main()